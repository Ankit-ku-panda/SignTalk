ğŸ“„ SignTalk â€“ Real-Time Sign Language Detection App
ğŸ“Œ Project Overview

SignTalk is an Android-based mobile application that detects real-time hand gestures representing sign language letters (Aâ€“Z) and converts them into readable text using Artificial Intelligence and Computer Vision.

The app uses the device camera and Google MediaPipe Hand Landmarker to recognize hand landmarks and interpret sign language gestures instantly.

This project is developed as a Final Year Engineering Project to assist communication between deaf-mute individuals and normal users.

ğŸ¯ Objectives

â€¢ Detect real-time hand gestures using mobile camera
â€¢ Recognize sign language letters (Aâ€“Z)
â€¢ Convert gestures into readable text
â€¢ Form words and sentences
â€¢ Provide real-time translation
â€¢ Assist deaf and mute communication

ğŸ§  Technologies Used
Technology	Purpose
Java	Android App Development
Android Studio	Development IDE
MediaPipe	Hand Gesture Detection
CameraX	Camera Integration
Machine Learning	Gesture Recognition
XML	UI Design
ğŸ“± Features

âœ… Real-time hand detection
âœ… Aâ€“Z letter recognition
âœ… Word formation
âœ… Live camera preview
âœ… Fast and lightweight
âœ… Works offline
âœ… User-friendly interface

ğŸ“· How It Works

User opens the app

Clicks "Open Camera"

Camera detects hand

MediaPipe identifies hand landmarks

App converts gesture to letter

Letters form words

Text displayed on screen

ğŸ—‚ Project Structure
SignTalk
â”‚
â”œâ”€â”€ app
â”‚   â”œâ”€â”€ java/com/example/signtalk
â”‚   â”‚      â”œâ”€â”€ MainActivity.java
â”‚   â”‚      â”œâ”€â”€ CameraActivity.java
â”‚   â”‚      â””â”€â”€ EmojiInterpreter.java
â”‚   â”‚
â”‚   â”œâ”€â”€ res
â”‚   â”‚      â”œâ”€â”€ layout
â”‚   â”‚      â””â”€â”€ drawable
â”‚   â”‚
â”‚   â”œâ”€â”€ assets
â”‚   â”‚      â””â”€â”€ hand_landmarker.task
â”‚
â””â”€â”€ README.md

âš™ Installation Guide
Step 1: Install APK

Copy:

app-release.apk


to your Android phone and install.

Step 2: Grant Camera Permission

Allow camera access when asked.

Step 3: Use App

Open app
Click:

Open Camera


Show hand gesture.

ğŸ’» Development Requirements

â€¢ Android Studio Hedgehog or later
â€¢ Java JDK 11
â€¢ Android SDK 33+
â€¢ Android Phone (Recommended)

ğŸ¤– Machine Learning Model

Model Used:

MediaPipe Hand Landmarker


File:

hand_landmarker.task


Location:

app/src/main/assets/

ğŸ“Š Expected Output

Example:

Gesture â†’ Output

âœŠ â†’ A
âœ‹ â†’ B
ğŸ‘Œ â†’ OK

Word Example:

A + B + C â†’ ABC

ğŸ“ Academic Use

This project is submitted as:

Final Year Engineering Project

Branch:

Computer Science / Information Technology

ğŸš€ Future Improvements

â€¢ Detect full sign language words
â€¢ Add speech output
â€¢ Add sentence prediction
â€¢ Add multi-language support
â€¢ Improve accuracy

ğŸ‘¨â€ğŸ’» Author

Name: Your Name
College: Your College Name
Year: Final Year
Project Name: SignTalk

ğŸ“œ License

This project is for educational purposes only.

ğŸ™ Acknowledgment

Special thanks to:

Google MediaPipe
Android Studio
Open Source Community

â­ Optional (Recommended)

Also create:

PROJECT_REPORT.docx


and

PRESENTATION.pptx
