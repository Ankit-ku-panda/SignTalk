

---

---

# ğŸ“Œ Project Overview

**SignTalk** is an AI-powered Android mobile application that detects **real-time sign language hand gestures (Aâ€“Z letters)** and converts them into **readable text** using **Computer Vision and Machine Learning**.

The application uses:

* ğŸ“· Mobile Camera
* ğŸ¤– Google MediaPipe Hand Landmarker
* ğŸ§  On-device AI Model
* ğŸ“± Android Studio (Java)

This project is developed as a:

> ğŸ“ **Final Year Engineering Project**

to help **deaf and mute individuals communicate easily with others.**

---

# ğŸ¯ Objectives

â€¢ Detect real-time hand gestures
â€¢ Recognize sign language letters (Aâ€“Z)
â€¢ Convert gestures to text
â€¢ Form words and sentences
â€¢ Provide real-time communication
â€¢ Work completely offline

---

# ğŸ§  Technologies Used

| Technology       | Purpose                 |
| ---------------- | ----------------------- |
| Java             | Android App Development |
| Android Studio   | Development IDE         |
| MediaPipe        | Hand Gesture Detection  |
| CameraX          | Camera Integration      |
| Machine Learning | Gesture Recognition     |
| XML              | UI Design               |

---

# ğŸ“± Features

âœ… Real-time hand detection
âœ… A-Z letter recognition
âœ… Word formation
âœ… Live camera preview
âœ… Fast performance
âœ… Offline working
âœ… User-friendly interface

---

# ğŸ“· App Workflow

```
User opens app
      â†“
Clicks "Open Camera"
      â†“
Camera detects hand
      â†“
MediaPipe detects landmarks
      â†“
AI identifies gesture
      â†“
Letter displayed
      â†“
Words formed
```

---

# ğŸ–¼ App Screenshots

## Main Screen

Shows buttons and translation

## Camera Screen

Detects hand gesture live

---

# ğŸ—‚ Project Structure

```
SignTalk
â”‚
â”œâ”€â”€ app
â”‚   â”‚
â”‚   â”œâ”€â”€ java/com/example/signtalk
â”‚   â”‚      â”‚
â”‚   â”‚      â”œâ”€â”€ MainActivity.java
â”‚   â”‚      â”œâ”€â”€ CameraActivity.java
â”‚   â”‚      â”œâ”€â”€ GestureClassifier.java
â”‚   â”‚      â””â”€â”€ EmojiInterpreter.java
â”‚   â”‚
â”‚   â”œâ”€â”€ res
â”‚   â”‚      â”œâ”€â”€ layout
â”‚   â”‚      â”œâ”€â”€ drawable
â”‚   â”‚      â””â”€â”€ values
â”‚   â”‚
â”‚   â”œâ”€â”€ assets
â”‚   â”‚      â””â”€â”€ hand_landmarker.task
â”‚
â””â”€â”€ README.md
```

---

# âš™ Installation Guide

---

## Method 1 â€” Install APK (Recommended)

### Step 1

Copy:

```
app-release.apk
```

to your Android phone

---

### Step 2

Install APK

---

### Step 3

Allow camera permission

---

### Step 4

Open App

Click:

```
Open Camera
```

Show hand gesture

---

# ğŸ’» Development Setup

Requirements:

â€¢ Android Studio Hedgehog or newer
â€¢ Java JDK 11
â€¢ Android SDK 33+
â€¢ Android Phone

---

# ğŸ¤– AI Model Used

Model:

```
MediaPipe Hand Landmarker
```

File:

```
hand_landmarker.task
```

Location:

```
app/src/main/assets/
```

---

# ğŸ“Š Example Output

| Gesture | Output |
| ------- | ------ |
| âœŠ       | A      |
| âœ‹       | B      |
| ğŸ‘Œ      | OK     |

Example:

```
A + B + C = ABC
```

---

# ğŸ“ Academic Details

Project Title:

SignTalk â€“ AI Assistive Communication System

Submitted for:

Final Year Engineering Project

Branch:

Computer Science / IT

---

# ğŸš€ Future Improvements

â€¢ Detect full sign language words
â€¢ Add speech output
â€¢ Add sentence prediction
â€¢ Add multiple languages
â€¢ Improve AI accuracy

---

# ğŸ‘¨â€ğŸ’» Author

Name: Ankit Kumar Panda
Project: SignTalk
Role: Developer

---

# ğŸ“œ License

This project is for:

Educational Purpose Only

---

# ğŸ™ Acknowledgment

Special thanks to:

Google MediaPipe
Android Studio
Open Source Community

---

# â­ How to Use This README

### Step 1

Open GitHub repo

### Step 2

Click:

README.md

### Step 3

Click:

Edit

### Step 4

Paste this code

### Step 5

Click:

Commit

---

# ğŸ‰ Your Final Year Project is now Professional Level

---

# If you want, I can also give:

âœ” Project Report DOCX
âœ” PPT Presentation
âœ” Final APK
âœ” GitHub Portfolio Setup

Just say: **"Send Full Project Bundle"**
